{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/camenduru/stable-cascade-jupyter/blob/main/stable_cascade_gradio_jupyter.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjYy0F2gZIPR"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "!git clone -b dev https://github.com/camenduru/stable-cascade-hf\n",
        "%cd /content/stable-cascade-hf\n",
        "\n",
        "!wget https://huggingface.co/spaces/multimodalart/stable-cascade/resolve/main/previewer/previewer_v1_100k.pt -O /content/stable-cascade-hf/previewer/previewer_v1_100k.pt\n",
        "!wget https://huggingface.co/spaces/multimodalart/stable-cascade/resolve/main/previewer/text2img_wurstchen_b_v1_previewer_100k.pt -O /content/stable-cascade-hf/previewer/text2img_wurstchen_b_v1_previewer_100k.pt\n",
        "\n",
        "!pip install -q git+https://github.com/kashif/diffusers.git@diffusers-yield-callback\n",
        "!pip install -q gradio accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "import torch\n",
        "from typing import List\n",
        "from diffusers.utils import numpy_to_pil\n",
        "from diffusers import StableCascadeDecoderPipeline, StableCascadePriorPipeline\n",
        "from diffusers.pipelines.wuerstchen import DEFAULT_STAGE_C_TIMESTEPS\n",
        "from previewer.modules import Previewer\n",
        "\n",
        "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
        "PREVIEW_IMAGES = True\n",
        "ENABLE_CPU_OFFLOAD = False\n",
        "USE_TORCH_COMPILE = False\n",
        "\n",
        "dtype = torch.bfloat16\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "if torch.cuda.is_available():\n",
        "    prior_pipeline = StableCascadePriorPipeline.from_pretrained(\"stabilityai/stable-cascade-prior\", torch_dtype=dtype)#.to(device)\n",
        "    decoder_pipeline = StableCascadeDecoderPipeline.from_pretrained(\"stabilityai/stable-cascade\",  torch_dtype=dtype)#.to(device) \n",
        "\n",
        "    if ENABLE_CPU_OFFLOAD:\n",
        "        prior_pipeline.enable_model_cpu_offload()\n",
        "        decoder_pipeline.enable_model_cpu_offload()\n",
        "    else:\n",
        "        prior_pipeline.to(device)\n",
        "        decoder_pipeline.to(device)\n",
        "\n",
        "    if USE_TORCH_COMPILE:\n",
        "        prior_pipeline.prior = torch.compile(prior_pipeline.prior, mode=\"reduce-overhead\", fullgraph=True)\n",
        "        decoder_pipeline.decoder = torch.compile(decoder_pipeline.decoder, mode=\"max-autotune\", fullgraph=True)\n",
        "    \n",
        "    if PREVIEW_IMAGES:\n",
        "        previewer = Previewer()\n",
        "        previewer_state_dict = torch.load(\"previewer/previewer_v1_100k.pt\", map_location=torch.device('cpu'))[\"state_dict\"]\n",
        "        previewer.load_state_dict(previewer_state_dict)\n",
        "        def callback_prior(i, t, latents):\n",
        "            output = previewer(latents)\n",
        "            output = numpy_to_pil(output.clamp(0, 1).permute(0, 2, 3, 1).float().cpu().numpy())\n",
        "            return output\n",
        "        callback_steps = 1\n",
        "    else:\n",
        "        previewer = None\n",
        "        callback_prior = None\n",
        "        callback_steps = None\n",
        "else:\n",
        "    prior_pipeline = None\n",
        "    decoder_pipeline = None\n",
        "\n",
        "\n",
        "def randomize_seed_fn(seed: int, randomize_seed: bool) -> int:\n",
        "    if randomize_seed:\n",
        "        seed = random.randint(0, MAX_SEED)\n",
        "    return seed\n",
        "\n",
        "def generate(\n",
        "    prompt: str,\n",
        "    negative_prompt: str = \"\",\n",
        "    seed: int = 0,\n",
        "    width: int = 1024,\n",
        "    height: int = 1024,\n",
        "    prior_num_inference_steps: int = 30,\n",
        "    # prior_timesteps: List[float] = None,\n",
        "    prior_guidance_scale: float = 4.0,\n",
        "    decoder_num_inference_steps: int = 12,\n",
        "    # decoder_timesteps: List[float] = None,\n",
        "    decoder_guidance_scale: float = 0.0,\n",
        "    num_images_per_prompt: int = 2,\n",
        "    profile: gr.OAuthProfile | None = None,\n",
        ") -> PIL.Image.Image:\n",
        "    previewer.eval().requires_grad_(False).to(device).to(dtype)\n",
        "    prior_pipeline.to(device)\n",
        "    decoder_pipeline.to(device)\n",
        "    \n",
        "    generator = torch.Generator().manual_seed(seed)\n",
        "    prior_output = prior_pipeline(\n",
        "        prompt=prompt,\n",
        "        height=height,\n",
        "        width=width,\n",
        "        num_inference_steps=prior_num_inference_steps,\n",
        "        timesteps=DEFAULT_STAGE_C_TIMESTEPS,\n",
        "        negative_prompt=negative_prompt,\n",
        "        guidance_scale=prior_guidance_scale,\n",
        "        num_images_per_prompt=num_images_per_prompt,\n",
        "        generator=generator,\n",
        "        callback=callback_prior,\n",
        "        callback_steps=callback_steps\n",
        "    )\n",
        "\n",
        "    if PREVIEW_IMAGES:\n",
        "        for _ in range(len(DEFAULT_STAGE_C_TIMESTEPS)):\n",
        "            r = next(prior_output)\n",
        "            if isinstance(r, list):\n",
        "                yield r[0]\n",
        "        prior_output = r\n",
        "\n",
        "    decoder_output = decoder_pipeline(\n",
        "        image_embeddings=prior_output.image_embeddings,\n",
        "        prompt=prompt,\n",
        "        num_inference_steps=decoder_num_inference_steps,\n",
        "        # timesteps=decoder_timesteps,\n",
        "        guidance_scale=decoder_guidance_scale,\n",
        "        negative_prompt=negative_prompt,\n",
        "        generator=generator,\n",
        "        output_type=\"pil\",\n",
        "    ).images\n",
        "\n",
        "    yield decoder_output[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "\n",
        "DESCRIPTION = \"# Stable Cascade\"\n",
        "DESCRIPTION += \"\\n<p style=\\\"text-align: center\\\">Unofficial demo for <a href='https://huggingface.co/stabilityai/stable-cascade' target='_blank'>Stable Casacade</a>, a new high resolution text-to-image model by Stability AI, built on the WÃ¼rstchen architecture - <a href='https://huggingface.co/stabilityai/stable-cascade/blob/main/LICENSE' target='_blank'>non-commercial research license</a></p>\"\n",
        "MAX_SEED = np.iinfo(np.int32).max\n",
        "CACHE_EXAMPLES = False\n",
        "MAX_IMAGE_SIZE = int(os.getenv(\"MAX_IMAGE_SIZE\", \"1536\"))\n",
        "\n",
        "examples = [\n",
        "    \"An astronaut riding a green horse\",\n",
        "    \"A mecha robot in a favela by Tarsila do Amaral\",\n",
        "    \"The sprirt of a Tamagotchi wandering in the city of Los Angeles\",\n",
        "    \"A delicious feijoada ramen dish\"\n",
        "]\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(DESCRIPTION)\n",
        "    gr.DuplicateButton(\n",
        "        value=\"Duplicate Space for private use\",\n",
        "        elem_id=\"duplicate-button\",\n",
        "        visible=os.getenv(\"SHOW_DUPLICATE_BUTTON\") == \"1\",\n",
        "    )\n",
        "    with gr.Group():\n",
        "        with gr.Row():\n",
        "            prompt = gr.Text(\n",
        "                label=\"Prompt\",\n",
        "                show_label=False,\n",
        "                max_lines=1,\n",
        "                placeholder=\"Enter your prompt\",\n",
        "                container=False,\n",
        "            )\n",
        "            run_button = gr.Button(\"Run\", scale=0)\n",
        "        result = gr.Image(label=\"Result\", show_label=False)\n",
        "    with gr.Accordion(\"Advanced options\", open=False):\n",
        "        negative_prompt = gr.Text(\n",
        "            label=\"Negative prompt\",\n",
        "            max_lines=1,\n",
        "            placeholder=\"Enter a Negative Prompt\",\n",
        "        )\n",
        "\n",
        "        seed = gr.Slider(\n",
        "            label=\"Seed\",\n",
        "            minimum=0,\n",
        "            maximum=MAX_SEED,\n",
        "            step=1,\n",
        "            value=0,\n",
        "        )\n",
        "        randomize_seed = gr.Checkbox(label=\"Randomize seed\", value=True)\n",
        "        with gr.Row():\n",
        "            width = gr.Slider(\n",
        "                label=\"Width\",\n",
        "                minimum=1024,\n",
        "                maximum=MAX_IMAGE_SIZE,\n",
        "                step=512,\n",
        "                value=1024,\n",
        "            )\n",
        "            height = gr.Slider(\n",
        "                label=\"Height\",\n",
        "                minimum=1024,\n",
        "                maximum=MAX_IMAGE_SIZE,\n",
        "                step=512,\n",
        "                value=1024,\n",
        "            )\n",
        "            num_images_per_prompt = gr.Slider(\n",
        "                label=\"Number of Images\",\n",
        "                minimum=1,\n",
        "                maximum=2,\n",
        "                step=1,\n",
        "                value=1,\n",
        "            )\n",
        "        with gr.Row():\n",
        "            prior_guidance_scale = gr.Slider(\n",
        "                label=\"Prior Guidance Scale\",\n",
        "                minimum=0,\n",
        "                maximum=20,\n",
        "                step=0.1,\n",
        "                value=4.0,\n",
        "            )\n",
        "            prior_num_inference_steps = gr.Slider(\n",
        "                label=\"Prior Inference Steps\",\n",
        "                minimum=10,\n",
        "                maximum=30,\n",
        "                step=1,\n",
        "                value=20,\n",
        "            )\n",
        "\n",
        "            decoder_guidance_scale = gr.Slider(\n",
        "                label=\"Decoder Guidance Scale\",\n",
        "                minimum=0,\n",
        "                maximum=0,\n",
        "                step=0.1,\n",
        "                value=0.0,\n",
        "            )\n",
        "            decoder_num_inference_steps = gr.Slider(\n",
        "                label=\"Decoder Inference Steps\",\n",
        "                minimum=4,\n",
        "                maximum=12,\n",
        "                step=1,\n",
        "                value=10,\n",
        "            )\n",
        "\n",
        "    gr.Examples(\n",
        "        examples=examples,\n",
        "        inputs=prompt,\n",
        "        outputs=result,\n",
        "        fn=generate,\n",
        "        cache_examples=CACHE_EXAMPLES,\n",
        "    )\n",
        "\n",
        "    inputs = [\n",
        "            prompt,\n",
        "            negative_prompt,\n",
        "            seed,\n",
        "            width,\n",
        "            height,\n",
        "            prior_num_inference_steps,\n",
        "            # prior_timesteps,\n",
        "            prior_guidance_scale,\n",
        "            decoder_num_inference_steps,\n",
        "            # decoder_timesteps,\n",
        "            decoder_guidance_scale,\n",
        "            num_images_per_prompt,\n",
        "    ]\n",
        "    gr.on(\n",
        "        triggers=[prompt.submit, negative_prompt.submit, run_button.click],\n",
        "        fn=randomize_seed_fn,\n",
        "        inputs=[seed, randomize_seed],\n",
        "        outputs=seed,\n",
        "        queue=False,\n",
        "        api_name=False,\n",
        "    ).then(\n",
        "        fn=generate,\n",
        "        inputs=inputs,\n",
        "        outputs=result,\n",
        "        api_name=\"run\",\n",
        "    )\n",
        "    \n",
        "# with gr.Blocks(css=\"style.css\") as demo_with_history:\n",
        "#     with gr.Tab(\"App\"):\n",
        "#         demo.render()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.queue().launch(share=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
